<script type="text/javascript">
  var disqus_identifier = "quake2";
</script>
<!DOCTYPE html>
<html>
	<head>	
		<meta http-equiv="content-type" content="text/html; charset=utf-8">
		<meta name="Author" content="Fabien Sanglard">
		
		<meta name="Keywords" content="Quake 2 Source Code Review"/>
		<meta name="Description" content="Quake 2 Source Code Review"/>
		<meta name="viewport" content="width=device-width, initial-scale=1">
	

		
		

 
 	
		
		<title>Quake 2 Source Code Review</title>
		
	</head>
	<body>
		<div id="main">
           
					
			<link rel='stylesheet' href='../css/neo_style.css' type='text/css'  />



    <h1 id="site-name">
        <a  href="../index.html" >Fabien Sanglard's Website</a>
    </h1>

<script>
   function setEmailTitle()
	{
 		var folders = window.location.href.split("/"); 

		var currentFolder = folders[folders.length-2];

		var emailLink = document.getElementById("mail");

		emailLink.href = "mailto:fabiensanglard.net@gmail.com?subject="+currentFolder;

	}
	
	window.onload = setEmailTitle;
</script>
<style type='text/css'>
		/**
		 * Bulletproof syntax:
		 * http://www.fontspring.com/blog/further-hardening-of-the-bulletproof-syntax
		 * Font files generated by Font Squirrel:
		 * http://www.fontsquirrel.com
		 * License: Open Font License. See http://evenchick.com/wp-content/themes/blaskan/OFL.txt.
		 */
		@font-face {
			font-family: 'LeagueGothic';
			src: url('../font/league_gothic/league_gothic-webfont.eot'); /* IE9 Compat Modes */
			src: url('../font/league_gothic/league_gothic-webfont.eot?iefix') format('eot'), /* IE6-IE8 */
			     url('../font/league_gothic/league_gothic-webfont.woff') format('woff'), /* Modern Browsers */
			     url('../font/league_gothic/league_gothic-webfont.ttf')  format('truetype'), /* Safari, Android, iOS */
			     url('../font/league_gothic/league_gothic-webfont.svg') format('svg'); /* Legacy iOS */
		}
		
		@font-face {
			font-family: 'DejaVu Sans';
			src: url('../font/dejavu-sans/DejaVuSansMono.ttf'); /* IE9 Compat Modes */
			src: url('../font/dejavu-sans/DejaVuSansMono.ttf')  format('truetype') /* Safari, Android, iOS */
			     
		}

		
</style>

<header id="header" role="banner"><nav id="nav" role="navigation"><div class="menu">
	<ul id="menu-primary-navigation-1" >
         <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-91">
           <a href="../index.html" >Home</a>
         </li>
         <li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-95">
           <a href="../about/index.html">About</a>
         </li>
          <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-96">
           <a href="../faq/index.html">FAQ</a>
         </li>
         <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-92">
            <a id="mail" href="mailto:fabiensanglard.net@gmail.com?subject=Tunnel" title="Send me an email.">Email</a>
         </li>
         <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-93">
            <a href="../rss.xml" title="Suscribe to RSS Feed.">Rss</a>
         </li>
         <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-94">
            <a href="http://twitter.com/fabynou" title="Follow me on Twitter.">Twitter</a>
         </li>
     </ul></div></nav></header>
<!-- / #header -->
<section id="content" role="main">



		
<link rel="alternate" type="application/rss+xml" title="Fabien Sanglard &raquo; Feed" href="../rss.xml" />
<link rel="alternate" type="application/rss+xml" title="Fabien Sanglard &raquo; Comments Feed" href="../rss.xml" />
<div id="date">
       September 16th, 2011</div>
   <h1>Quake 2 Source Code Review 4/4</h1>
   <p id="paperbox">
	   	
          <a  href="index.php">
          <img src="quake2_icon.jpg" style="margin-left: 2ch;float:right; border:1px black solid;width:35%;">   
          </a> 
         
<br/>
<a href="index.php">Quake 2 Source Code Review 1/4 (Intro) </a><br/>			
<a href="quake2Polymorphism.php">Quake 2 Source Code Review 2/4 (Polymorphism) </a><br/>
<a href="quake2_software_renderer.php">Quake 2 Source Code Review 3/4 (Software Renderer)</a><br/>
<a href="quake2_opengl_renderer.php">Quake 2 Source Code Review 4/4 (OpenGL Renderer)</a><br/>
<br/></p>
<div style="clear:both;"></div>


<style> 

  table.credits { width:70%; a:link:color:rgb(0, 136, 204);}
  table.credits thead { background:transparent; }
  
  table.credits th { white-space:nowrap; }
  table.credits thead th { border-left:1px solid #ccc;  border-top:1px solid #ccc; padding:9px 9px 3px; color:#999; }
  table.credits tbody th,
  table.credits tbody td { border-top:1px solid #ccc; padding:6px 9px; }
  table.credits tbody th { padding:7px 0 7px 0; text-align:center; color:#999; }
  table.credits tbody th b { color:#333; font-weight:normal; }
  table.credits tbody td { border-left:1px solid #ccc; width:182px; }
  table.col3 tbody td { width:248px; }
  table.col2 tbody td { width:382px; }
  table.credits tbody .session { background:#d4e6fa url(session_bgblue.png) repeat-x 0 0; }
  table.credits tbody .session.alt { background:#e9ecf0 url(session_bggray.png) repeat-x 0 0; }
  table.credits tbody .session h3 { font-size:1em; margin-bottom:0; color:rgb(0, 136, 204); }
  table.credits tbody .session .hud-content { display:none; }

  
  blockquote.style1 
  {
      margin-right: auto;
      margin-left: auto;

      padding: 8px;
      
      width: 80%;
      
      background-color: #eeeeee;
      border: 1px solid #dddddd;
      
      
      margin: 5px;
      background-image: url(images/openquote1.gif);
      background-position: top left;
      background-repeat: no-repeat;
      text-indent: 23px;
    
    }
    
    blockquote.style1 span 
    {
      width:100%;
       margin-right: auto;
      margin-left: auto;
      display: block;
      font-style:italic;
      background-image: url(images/closequote1.gif);
      background-repeat: no-repeat;
      background-position: bottom right;
      text-align: justify;
    }
    
    
  </style> 


<h3>OpenGL Renderer</h3>

<p id="paperbox">
<img src="../fd_proxy/quake2/glRendererStruct.png" style="float:left; margin: 0px 10px 10px 0px;"/>

Quake2 was the first engine to ship with native support for hardware accelerated rendition. It demonstrated the 
undeniable gain through bilinear texture filtering, multitexturing increase and 24bits color blending.<br/>
<br/>
<center><img width="732px" src="../fd_proxy/quake2/renderer.gif"/><br/></center>
</br>
</br>
<p>
From an <b>user perspective</b> the hardware accelerated version provided the following improvements:
<ul>
  <li>Bilinear filtering</li>
  <li>Colored lighting</li>
  <li>30% framerate increase at a higher resolution</li>
</ul>
<br/>
<p>
I can't resist but to quote page 191 of "Masters of Doom" relating John Romero discovering colored lighting for the first time:<br/>
<br/>
<blockquote class="style1">
<br/>
<span>
<br/>
When Romero wandered over to id's booth, [...].<br/>
<br/>

He pushed his way through the crowd to see the demo of Quake II. His
face filled with yellow light as his jaw slackened. <b>Colored lighting!</b> Romero
couldn't believe what he was seeing. The setting was a dungeonlike military
level, but when the gamer fired his gun, the yellow blast of the ammunition
cast a corresponding yellow glow as it sailed down the walls. It was subtle,
but when Romero saw the dynamic colored lighting, it was a moment just
like that one back at Softdisk when he saw Dangerous Dave in Copyright
Infringement for the first time.<br/>
<br/>
"Holy f*ck," he muttered. Carmack had done it again.
<br/>
<br/>
</span>
</blockquote>
<br/>
<p>
This feature alone had a profound impact on the development of Daikatana.<br/>
<br/>
From a <b>code perspective</b>, the renderer is 50% smaller than the software renderer (see the "Code Statistics" at the end of the page). If this meant less work for the developer
it also mean this implementation is much less subtle and elegant than the software/assembly optimized version:
<ul>
  <li>The Z-Buffer removed the need for an Active Polygon Stack (this high reliance on a fast Z-buffer resulted in issues during the development of
  VQuake for V2200 (<a href="http://groups.google.com/group/comp.sys.ibm.pc.hardware.video/msg/4d9ce71f1e1f6484">A few words by one of the dev Stefan Podell</a> 
  (<a href="quake-v2x00_discussion.zip">mirror</a>) )</li>
  <li>The raw speed of the rasterizer chips combined to the speed of the Z-Buffer RAM voided the quest for zero overdraw.</li>
  <li>The GPU integrated scanline routine removed the need for a Global Edge Table and an Active Edge Table.</li>
  <li>Lightmap filtering being done on the GPU (and with RGB instead of grayscale): No trace of this on the CPU.</li>
</ul>
<br/>
<p>
In the end the OpenGL renderer is more of a resource manager than a renderer: sending vertices, uploading 
lightmaps atlas on the fly with and setting texture states.</br>
</br>
<b><u>Trivia :</u></b> A typical frame in Quake2 is 600-900 polygons: A far cry from 2011 millions of polygons in 
any game engine.<br/>
</p>







































<h3>Code Global Architecture</h3>

<p id="paperbox">
The rendering phase is very simple and I won't detail it since it is very very similar to the software renderer:
<pre class="long">

        R_RenderView
        {
          
            R_PushDlights          // Mark polygon affected by dynamic light
            R_SetupFrame
            R_SetFrustum
            R_SetupGL              // Setup GL_MODELVIEW and GL_PROJECTION
            
            R_MarkLeaves           // Decompress the PVS and mark potentially Visible Polygons
            
            R_DrawWorld            // Render Map, cull entire clusters of polygons via BoundingBox Testing
            {
               
            }
            
            R_DrawEntitiesOnList   // Render entities

            R_RenderDlights        // Blend dynamic lights
    
            R_DrawParticles        // Draw particles

            R_DrawAlphaSurfaces    // Alpha blend translucent surfaces

            R_Flash                // Post effects (full screen red for damage, etc...)
        }


</pre>

<p>
All the stages are visible in the following video where the engine was "slowed down":<br/>
<br/> 
<table><tr><td align="center"> 

<video width="900" height="675" preload="none" poster="../fd_proxy/quake2/openGL/2681/2681-poster.jpg" controls>
  <source src="../fd_proxy/quake2/openGL/2681/2681-Desktop.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>
</td></tr></table> 
<br/> 
<br/>
Rendition order:
<ul>
  <li>World.</li>
  <li>Entities (they are called "alias" in Quake2).</li>
  <li>Particles.</li>
  <li>Translucent surfaces.</li>
  <li>Post-effect full screen.</li>
</ul>
<br/>
<p>
 Most of the code complexity comes from different paths used whether the graphic card supports multitexturing and if batch vertex rendering is enabled: As 
 an example if multitexturing is supported <code>DrawTextureChains</code> and <code>R_BlendLightmaps</code> do nothing but confuse the reader in the following code sample:<br/>
</p>


<pre class="long">

        R_DrawWorld
        {
            //Draw the world, 100% completed if Multitexturing is supported or only pass ONE (color )if not Multitexturing

            R_RecursiveWorldNode    // Store faces by texture chain in order to avoid texture bind changes
            {
                //Render all PVS with cluster reject via BBox/Frustrum culling
                //Stuff is done here !! 
                
                //If visible: render
                GL_RenderLightmappedPoly
                {
                   if ( is_dynamic )
                   {
                    
                   }
                   else
                   {
                    
                   }
                }
            }
            
            //Only if no Multlitexturing supported (pass TWO)
            DrawTextureChains        // Draw all textures chains, this avoid calling bindTexture too many times.
            {
                for ( i = 0, image=gltextures ; i&lt;numgltextures ; i++,image++)
                for ( ; s ; s=s-&gt;texturechain)
                    R_RenderBrushPoly (s)
                    {
                    }
            }
            
            //Only if no Multlitexturing supported (pass TWO: lightmaps)
            R_BlendLightmaps
            {
                //Render static lightmaps
                
                //Upload and render dynamic lightmaps
                if ( gl_dynamic->value )
                {
                LM_InitBlock
                GL_Bind
                for ( surf = gl_lms.lightmap_surfaces[0]; surf != 0; surf = surf->lightmapchain )
                {
                    //Check if the block is full.
                        If full,
                         upload the block and draw
                        else
                        keep on pushing 
                    
                }
                }
            }
            
            R_DrawSkyBox
            
            R_DrawTriangleOutlines
        }
       
</pre>            
</p>

























<h3>World rendition</h3>

<p id="paperbox">
Rendering the map is done in <code>R_DrawWorld</code>. A vertex has five attributes:
<ul>
  <li>Position.</li>
  <li>Color textureID.</li>
  <li>Color texture coordinates.</li>
  <li>Static Lightmap textureID.</li>
  <li>Static Lightmap texture coordinates.</li>
</ul>
<p>
They are no "Surface" in the OpenGL renderer: color and lightmap are combined on the fly and never cached.
If the graphic card supports multi-texturing only one pass is necessary, specifying both textureID 
and textureCoordinates:<br/>
<ol>
  <li>Color texture is bound to OpenGL state GL_TEXTURE0.</li>
  <li>Lightmap texture is bound to OpenGL state GL_TEXTURE1.</li>
  <li>Vertices are sent with color and lightmap texture coordinate.</li>
</ol>
<br/>
<p>
If the graphic card DO NOT supports multi-texturing two passes are done:
<ol>
  <li>Blending is disabled.</li>
  <li>Color texture is bound to OpenGL state GL_TEXTURE0.</li>
  <li>Vertices are sent with color texture coordinate.</li>
  <li>Blending is enabled.</li>
  <li>Lightmap texture is bound to OpenGL state GL_TEXTURE0.</li>
  <li>Vertices are sent with lightmap texture coordinate.</li>  
</ol>





</p>











<h3>Textures management</h3>

<p id="paperbox">
  Since all of the rasterization is done on the GPU, all textures necessary are uploaded to VRAM at the beginning of a level:<br/>
  <ul>
    <li>Color textures</li>
    <li>Precalculated lightmaps textures</li>
  </ul>
  <p>
  Using gDEBugger OpenGL debugger it is easy to pock at the GPU memory and get some stats:<br/>
  <br/>
  <img src="../fd_proxy/quake2/openGL/gDEBugger.jpg" style="display: block; margin-left: auto;margin-right: auto;"/><br/>
  <br/>
  <p>We can see that each color texture as its own textureID. Static lightmaps are uploaded as texture-atlas (called "Block" in quake2) as follow:<br/>
  <br/>
  <img src="../fd_proxy/quake2/openGL/quake2-Context1-Texture1025level0.png" style="display: block; margin-left: auto;margin-right: auto;"/>
  <br/>
  <br/>

  So why are color Texture in their own texture unit while lightmap are aggregated in texture atlas ?<br/>
  The reason is <b>Texture chain optimizations</b> :<br/>
<br/>
If you want to increase performances with the GPU you should try to avoid changing its state as much as possible. 
This is especially true with texture binding (<code>glBindTexture </code>). Here is a bad example:<br/>
<pre class="long">
    

     for(i=0 ; i &lt; polys.num ; i++)     
     {
         glBindTexture(polys[i].textureColorID , GL_TEXTURE0);
         glBindTexture(polys[i].textureLightMapID , GL_TEXTURE1);
         RenderPoly(polys[i].vertices);
     }
     
     
</pre>
<br/>
<p>
If each polygon has a color texture and a lightmap texture there is very little that can be done but Quake2 organized its
lightmap in textureAtlas which are easy to group by id. So polygons are not rendered in the order they are returned from the BSP. 
Instead they are grouped in texturechains based on the lightmap texture atlas they belong to:

<pre class="long">
    
     glBindTexture(polys[textureChain[0]].textureLightMapID , GL_TEXTURE1);
  
     for(i=0 ; i &lt; textureChain.num ; i++)     
     {
         glBindTexture(polys[textureChain[i]].textureColorID , GL_TEXTURE0);
         RenderPoly(polys[textureChain[i]].vertices);
     }
     
     
</pre>


  
  
  
  <br/>
  <br/>
  <p>
  The following video really illustrate the "texture chain" rendition process: 
  Polygons are not rendered based on distance but rather on what lightmap block they belong to:<br/>
  <br/>
  <table><tr><td align="center"> 

<video width="900" height="675" preload="none" poster="../fd_proxy/quake2/openGL/2583/2583-poster.jpg" controls>
  <source src="../fd_proxy/quake2/openGL/2583/2583-Desktop.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>
</td></tr></table> 
<br/> 
<p>
<u><b>Note :</b></u> In order to achieve consistent translucency only opaque polygons were falling in the
texture chain sink, translucent poly are still rendered far to near.
</p>













<h3>Dynamic lighting </h3>

<p id="paperbox">
At the very beginning of the rendition phase, all polygons are marked in order to show is they are subject to
 dynamic lighting (<code>R_PushDlights</code>). If so, the precalculated static lightmap is not used but instead 
 a new lightmap is generated combining the static lightmap and adding the light projected on the polygon plan (<code>R_BuildLightMap</code>).<br/>
<br/>
Since a lightmap maximum dimension is 17x17 the dynamic lightmap generation phase is not
too costy..but uploading the change to the GPU with <code>qglTexSubImage2D</code> is VERY slow.<br/>
<br/>
A 128x128 lightmap block is dedicated to store all dynamic lightmaps: id=1024. See "Lightmap management"
to see how all dynamic lightmap were combined in a texture atlas on the fly.<br/>
<br/>
<br/>
  <img id="dyn_lightmap_img" src="../fd_proxy/quake2/openGL/quake2-Context1-Texture1024level0.png" style="display: block; margin-left: auto;margin-right: auto;"/>
<script>
var lightmapArray = new Array(
"/fd_proxy/quake2/openGL/quake2-Context1-Texture1024level0-0.png",
"/fd_proxy/quake2/openGL/quake2-Context1-Texture1024level0-1.png",
"/fd_proxy/quake2/openGL/quake2-Context1-Texture1024level0-2.png"
);
var DYN_LIGHTMAPS_NUM = 3;
var currentLightMapColor = 0;

function stepLightMap()
{
  currentLightMapColor++;
  currentLightMapColor = currentLightMapColor % DYN_LIGHTMAPS_NUM;
  document.getElementById("dyn_lightmap_img").src = lightmapArray[currentLightMapColor];
  setTimeout(stepLightMap,4000); 
}
stepLightMap();
</script>
<br/><br/><br/><br/><br/>
<br/>
<u>Note :</u> If the dynamic lightmap is full, a rendition batch is performed. The rover keeping track of allocated space is reset and 
dynamic lightmap generation resumes.
</p>






































<h3>Lightmap managment</h3>

<p id="paperbox">
As stated earlier, there is no concept of "surface" in the OpenGL version: Lightmap and color texture were combined on the fly and NOT cached.<br/>
Even though static lightmap are uploaded to the VRAM they are still kept in RAM: If a polygon is subject to a dynamic light, a new lightmap is generated
combining the static lightmap with the light projected onto it. The dynamic lightmap is then uploaded to textureId=1024 and used for texturing.<br/>
<br/>
Texture atlas were actually called "Block" in Quake2, all 128x128 texels and handled with three functions:
<ul>
  <li><code>LM_InitBlock</code> : Reset the block memory consumption tracking.</code>
  <li><code>LM_UploadBlock</code> : Upload or Update a texture content.</code>
  <li><code>LM_AllocBlock</code> : Find a suitable location to store a lightmap.</code>
</ul>
<p>

<br/>
The next video illustrate how lightmaps are combined into a Block. The engine is playing a little game of tetris here, scanning
 from left to right all the way an remembering where the lightmap fits entirely at the highest location in the image.<br/>
<br/>
<table><tr><td align="center"> 

<video width="750" height="675" preload="none" poster="../fd_proxy/quake2/openGL/quake2-Context1-Texture1025level0.png" controls>
  <source src="../fd_proxy/quake2/openGL/lightmapGen/lightmapGen-Desktop.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>
</td></tr></table> 
<br/>
The algorithm is noteworthy: A rover (<code>int gl_lms.allocated[BLOCK_WIDTH]</code>) keeps tracks of what height has been consumed for each column of pixels all width long.<br/>
<br/>
<pre class="long">

    // "best"  variable would have been better called "bestHeight"
    // "best2" vatiable would have been  MUST better called "tentativeHeight"
   
    static qboolean LM_AllocBlock (int w, int h, int *x, int *y)
    {
        int        i, j;
        int        best, best2;

        //FCS: At what height store the new lightmap
        best = BLOCK_HEIGHT;

        for (i=0 ; i&lt;BLOCK_WIDTH-w ; i++)
        {
            best2 = 0;

            for (j=0 ; j&lt;w ; j++)
            {
                if (gl_lms.allocated[i+j] &gt;= best)
                    break;
                if (gl_lms.allocated[i+j] &gt; best2)
                    best2 = gl_lms.allocated[i+j];
            }
            if (j == w)
            { // this is a valid spot
                *x = i;
                *y = best = best2;
            }
        }

        if (best + h &gt; BLOCK_HEIGHT)
            return false;

        for (i=0 ; i&lt;w ; i++)
            gl_lms.allocated[*x + i] = best + h;

      return true;
  
    }
    


</pre>
<p>
Note: The "rover" design pattern is very elegant and is also used in the software surface caching memory system.

</p>































<h3>Fillrate and rendition passes.</h3>

<p id="paperbox">
As you can see in the next video, the overdraw could be quite substantial:<br/>
<br/>
<br/> 
<table><tr><td align="center"> 

<video width="900" height="675" preload="none" poster="../fd_proxy/quake2/openGL/2606/2606-poster.jpg" controls>
  <source src="../fd_proxy/quake2/openGL/2606/2606-Desktop.m4v" type="video/mp4">
  Your browser does not support the video tag.
</video>
</td></tr></table> 
<br/> 
<br/>
In the worse case scenario a pixel could be written 3-4 times (not counting overdraw):
<ul>
  <li>World: 1-2 passes (depending on multitexturing).</li>
  <li>Particles blending: 1 pass.</<li> 
  <li>Post-effect blending: 1 pass.</<li>
</ul
<p>
</p>


















<h3>GL_LINEAR</h3>

<p id="paperbox">
  Bilinear filtering was good when used on the color texture but it really shone when filtering the lightmaps:<br/>
  <br/>
  <img id="3colors" src="3colors_00.jpg" style="display: block; margin-left: auto;margin-right: auto;"/>
<script>
var colorArray = new Array("3colors_00.jpg","3colors_01.jpg");
var COLOR_NUM = 2;
var currentImageColor = 0;

function stepAhead()
{
  currentImageColor++;
  currentImageColor = currentImageColor % COLOR_NUM;
  document.getElementById("3colors").src = colorArray[currentImageColor];
  setTimeout(stepAhead,3500); 
}
stepAhead();
</script>
<br/>
<p>
All together:<br/>
</p>
<br/>
<img id="full_pipeline" src="full_pipeline01.jpg" style="display: block; margin-left: auto;margin-right: auto;"/>
<script>
var fullPipelineArray = new Array(
"/fd_proxy/quake2/openGL/full_pipeline01_annotated.jpg",
"/fd_proxy/quake2/openGL/full_pipeline02_annotated.jpg",
"/fd_proxy/quake2/openGL/full_pipeline03_annotated.jpg");

var FULL_PIPELINE_NUM = 3;
var currentfullPipeline = 0;

function stepAheadFullPipeline()
{
  currentfullPipeline++;
  currentfullPipeline = currentfullPipeline % FULL_PIPELINE_NUM;
  document.getElementById("full_pipeline").src = fullPipelineArray[currentfullPipeline];
  setTimeout(stepAheadFullPipeline,3500); 
}
stepAheadFullPipeline();
</script>

</p>

















































<h3>Entities rendition</h3>

<p id="paperbox">

Entities are rendered via batches: vertices, texture coordinate and color array pointers are setup and everything is sent via a <code>
glArrayElement</code>.<br/>
<br/>
Before rendition, all entities vertices are lerped for smooth animation (only keyframes were used in Quake1).<br/>
<br/>
The lighting model is Gouraud: the color array is hijacked by Quake2 to store lighting value. 
Before rendition the lighting value is calculated for each vertex and stored in the color array. This color value
is interpolated on the GPU for a nice Gouraud result.<br/>
<br/>
<pre class="long">

    R_DrawEntitiesOnList 
    {
        if (!r_drawentities->value)
            return;

        // Non-transparent entities
        for (i=0 ; i &lt; r_newrefdef.num_entities ; i++)
        {
          R_DrawAliasModel
          {
            R_LightPoint    /// Determine color of the light to apply to the entire model
            GL_Bind(skin->texnum);  //Bind entitiy texture
            
            GL_DrawAliasFrameLerp()  //Draw
            {
              GL_LerpVerts //LERP interpolation of all vertices
              
              // Calculate light for each vertices, store it in colorArray
              for ( i = 0; i &lt; paliashdr->num_xyz; i++ )
              {
              }
              
              qglLockArraysEXT
              qglArrayElement       // DRAW !!
              qglUnlockArraysEXT
            }
          }
        }
        
        
        
        // Transparent entities
        for (i=0 ; i &lt; r_newrefdef.num_entities ; i++)
        {
          R_DrawAliasModel
          {
            [...]
          }
        }
        
        
        
    }

</pre>
<br/>
Backface culling is performed on the GPU (well since T&L was still done on CPU at the 
time I guess we can say it was done in the driver stage).<br/>
<br/>
<u><b>Note :</b></u> In order to speed things up the light direction used for calculation is always the same (<code>{-1, 0, 0}</code> ) but it does not show in the engine. The color of the light
is accurate and is picked via the current poly the entity is resting on.<br/>
<br/>
This can be seen very well in the next screen shot were the light and shadow are all in the same direction even though the light source are inconsistent.<br/>
<br/>
  <img src="shadow_issue_zoom.jpg"/>
<br/>
<br/>
<u><b>Note:</b></u> Of course it is not always perfect, shadow extend over the void and faces overwrite each other, causing different level of shadow but still pretty impressive for 1997.
<br/>
<br/>
<u>More on shadows :</u>
<br/>
Unknown to a lot of people, Quake2 was able to calculate crude shadows for entities. Although disabled by default, this feature can be activated via the command <code>gl_shadows 1</code>.<br/>
<br/>
The shadow always go in the same direction (not based on closest light), faces are projected on the entity level plane. In the code, <code>R_DrawAliasModel</code> generate a <code>shadevector</code> that is used in <code>GL_DrawAliasShadow</code> to perform the face projection on the entity level plan.<br/>

<br/>
</p>











<h3>Entities rendition lighting: The quantization trick</h3>

<p id="paperbox">
You may think that the low number of polygons in an alias would have allowed to calculate normal and dot product normal/light in real time....but NO.
All dotproduct are precalculated and stored in <code>float  r_avertexnormal_dots[SHADEDOT_QUANT][256]</code>, where <code>SHADEDOT_QUANT</code>=16.<br/>
<br/>
Quantization is used: The light direction is always the same: {-1,0,0}.<br/>
Only 16 different set of normals are calculated, depending on the Y orientation of the model.<br/>
Once one of the 16 orientation is selected the dotproduct are precomputed for 256 different normals. A normal in MD2 model format is ALWAYS an index in the precomputed array.
Any combination of X,Y,Z normal falls in one of the 256 directions.<br/>
<br/>
<br/>
With all those limitations, all dotproduct are looked up from the 16x256 <code>r_avertexnormal_dots</code>. Since normal index cannot interpolated in the animation process the closest normal index from a keyframe is used. <br/>
<br/>
More to read about this: <a href="http://www.quake-1.com/docs/quakesrc.org/97.html">http://www.quake-1.com/docs/quakesrc.org/97.html</a> 
<a href="modQuantization.zip">mirror</a>) .<br/>
</p>

















<h3>Old Old OpenGL...</h3>

<p id="paperbox">
<u>Where is my glGenTextures ?!:</u><br/>
<br/>
Nowaday an openGL developer request a textureID from the GPU with <code>glGenTextures</code>. Quake2 doesn't bother
doing this and unilateraly decide of an ID. So color textures start at 0, the dynamic lightmap texture is always 1024 and
the static lighmap are 1025 up to 1036.<br/>
<br/>

<u>Infamous Immediate mode :</u><br/>
<br/>
<p id="paperbox">
Vertices data are passed to the video card via ImmediateMode. Two function calls per vertex <code>glVertex3fv</code> 
and <code>glTexCoord2f</code> for the world rendition (because polygons were culled individually there was no way
to batch them).<br/>
<br/>
Batch rendition is performed for aliasModels (enemies,players) with <code>glEnableClientState( GL_VERTEX_ARRAY )</code>.
Vertices are sent to <code>glVertexPointer</code> and <code>glColorPointer</code> is used to pass the lighting value
calculated on the CPU.<br/>
<br/>
<u>Multitexturing :</u><br/>
<br/>
The code is complicated by trying to accommodate hardwares with and without support for the brand new...multitexturing.<br/>
<br/>

<br/>
<u>No usage of <code>GL_LIGHTING</code> :</u><br/>
<br/>
Since all lighting calculations were performed on CPU (texture generation for the world and vertex light value for entities) there are no traces of <code>GL_LIGHTING</code> 
in the code.<br/>
Since OpenGL 1.0 was doing Gourant shading anyway (by interpolating color across vertex) instead of Phong (where normal are interpolated for a real "per-pixel-lighting") 
to use <code>GL_LIGHTING</code> would have not looked good for the world since it would have required to create vertices on the fly.<br/>
<br/>
It "could" have been done for entities but at the cost of also sending vertices normal vectors . It seems this was ruled against and hence
 lighting value calculation is performed on the CPU. Lighting value are passed in the color array, values are interpolated on the GPU for a Gouraud result.<br/>

<br/>
<!--
<img src="lightmap.jpg" style="display: block; margin-left: auto;margin-right: auto;"/>
-->
</p>






























<h3>Fullscreen Post-effects</h3>

<p id="paperbox">
The palette based software renderer did an elegant full palette colord blending with an optionnal Gamma correction with lookup table but the OpenGL version doesn't care about this and you can
see it is again using a bruteforce approach in <code>R_Flash</code>:<br/>
<br/>
<u>Problem :</u> You want the screen to be a little big more red ?<br/>
<u>Solution :</u> Just draw a gigantic red GL_QUAD with alpha blending enabled all over the screen. Done.<br/>
<br/>
<u>Note :</u> The Server was driving the Client just like the software renderer: If any part of the Server
wanted to have a post-effect full screen color blended it just had to set the RGBA <code>float player_state_t.blend[4]</code> variable. The variable value
then transited over the network thanks to the quake2 kernel and was sent to the renderer DLL.
</p>

















<h3>Profiling</h3>

<p id="paperbox">
Visual Studio 2008 Team's profiler is dreamy, here are what came up with Quake2 OpenGL:<br/>
<br/>
<img src="../fd_proxy/quake2/openGL/openGL_profiler.jpg" style="display: block; margin-left: auto;margin-right: auto;"/><br/>
<br/>
This is not a surprise: Most of the time is spent in the NVidia and Win32's OpenGL driver (<code>nvoglv32.dll</code> and <code>opengl32.dll</code>) 
for a total of 30%. Rendition is done on the GPU but A LOT OF TIME is wasted via the immediate mode's many method calls and also to copy the data from RAM to VRAM.<br/>
<br/>
Next comes the renderer module (<code>ref_gl.dll</code> 23%) and the quake2 kernel (<code>quake2.exe</code> 15%).<br/>
<br/>
Even though the engine is relying massively on malloc, we can see that the time spent there is almost inexistant (<code>MSVCR90D.dll</code> 
and <code>msvcrt.dll</code>).
Also non-existant, the time spent in the game logic (<code>gamex86.dll</code>).<br/>
<br/>
A surprising amount of time is spent in the directX's sound library (<code>dsound.dll</code>) for 12% of cumulated time.<br/>
<Br/>
If we take a closer look to Quake2 OpenGL renderer dll:<br/>
<br/>
<img src="../fd_proxy/quake2/openGL/openGL_profiler_rend_dll_module.jpg" style="display: block; margin-left: auto;margin-right: auto;"/><br/>
<br/>
<ul>
<li>Most of the time is spent rendering the world (<code>R_RecurseiveWorldNode</code>). 
<li>Close second is to render enemies (alias models): (<code>GL_DrawAliasFrameLerp</code> 2.5%). The cost is quite high even
 though all dot product are precalculated as seen before.
 <li>Lightmap generation (when a dynamic light prevent usage of the static precalculated lightmap) also represent 2.5%  (<code>GL_RenderLightMappedPoly</code>).
</ul>
<p>
Overall the OpenGL dll is well balanced, there are NO obvious bottlenecks.
</p>





















<h3>Code Statistics</h3>

<p id="paperbox">

Code analysis by Cloc shows a total of 7,265 lines of code.

<pre class="long">

    $ cloc ref_gl
          17 text files.
          17 unique files.
           1 file ignored.

    http://cloc.sourceforge.net v 1.53  T=1.0 s (16.0 files/s, 10602.0 lines/s)
    -------------------------------------------------------------------------------
    Language                     files          blank        comment           code
    -------------------------------------------------------------------------------
    C                                9           1522           1403           6201
    C/C++ Header                     6            237            175           1062
    Teamcenter def                   1              0              0              2
    -------------------------------------------------------------------------------
    SUM:                            16           1759           1578           7265
    -------------------------------------------------------------------------------


</pre>
<p>
The difference is striking when comparing to the software renderer: 50% less code, NO assembly optimization for a result that is 30% faster and features colored lighting and bilinear filtering.
It is easy to understand why id Software did not bother shipping an software renderer in Quake3.
</p>
</p>




























<!-- <h2>Comments</h2>
<p> -->


     <!-- <div id="disqus_thread"></div> -->
    <!-- <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'fabiensanglardswebsite'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || 
                document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> -->
    <!--<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a> -->
<!--     




</p> -->

 <h2 style="padding: 0px; margin: 0px;">&nbsp;</h2>
<div style="text-align:center ;">@</div>

		</div>
</div>

	<script src="../lazy_load/jquery.min.js" type="text/javascript" charset="utf-8"></script>
 	

  	<script src="../lazy_load/jquery.lazyload.min.js?v=3" type="text/javascript" charset="utf-8"></script>
	<script type="text/javascript" charset="utf-8">
		      $(function() {
		          $("img").lazyload({
		              effect : "fadeIn"
		          });
		      });
    </script>	
	</body>

</html>

