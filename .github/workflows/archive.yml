---

name: "Archive Link"
run-name: "Archiving ${{ inputs.url }}"

on:

  workflow_dispatch:
    inputs:
      url:
        required: true
        type: string
        description: |
          The url to archive.

          By default, only the file specified will be archived.
          If the url ends with a `/` then it will be treated like a directory and will be mirrored.

  workflow_call:
    inputs:
      url:
        required: true
        type: string
        description: |
          The url to archive.

          By default, only the file specified will be archived.
          If the url ends with a `/` then it will be treated like a directory and will be mirrored.

    secrets:
      AUTO_DOWNLOAD_ARCHIVE: { required: true }
      AUTO_COMMIT_GPG_PRIVATE_KEY_ARCHIVE: { required: true }
      AUTO_COMMIT_GPG_PASSPHRASE_ARCHIVE: { required: true }

env:
  GH_TOKEN: ${{ secrets.AUTO_DOWNLOAD_ARCHIVE }}

jobs:
  archive-directory:
    if: ${{ endsWith(inputs.url, '/') }}
    name: Archive Directory
    runs-on: ubuntu-latest
    timeout-minutes: 660
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.AUTO_DOWNLOAD_ARCHIVE }}

      - name: Setup GPG Keys
        uses: crazy-max/ghaction-import-gpg@v5
        with:
          gpg_private_key: ${{ secrets.AUTO_COMMIT_GPG_PRIVATE_KEY_ARCHIVE }}
          passphrase: ${{ secrets.AUTO_COMMIT_GPG_PASSPHRASE_ARCHIVE }}
          git_user_signingkey: true
          git_commit_gpgsign: true

      - name: Determine Target
        id: target
        env: { URL: '${{ inputs.url }}' }
        run: |
          grep --invert "^#" << EOF | tee -a "${GITHUB_OUTPUT}"

          # Get the directory being saved
          directory=$(
            echo "${URL}" |
              python3 -c "import sys; from urllib.parse import unquote; print(unquote(sys.stdin.read()));" |
              sed -E 's/^https?:\/\/web.archive.org\/web\/[0-9]+\/(https?:\/\/)?/https:\/\//' |
              sed -E 's/^https?:\/\///' |
              sed -E 's/^ftps?:\/\///' |
              sed -E 's/^ia[0-9]+.us.archive.org\/[0-9]+\/items\//archive.org\/download\//'
          )

          # Get the url of the file (with any sanitisation)
          url=$(
            echo "${URL}"
          )

          # Get the branch that this url will be archived via
          branch=$(
            echo "archive/${{ github.run_id }}-${{ github.run_number }}-${{ github.run_attempt }}-$(openssl rand -hex 8)"
          )

          EOF

      - name: Mirror Directory
        continue-on-error: true # Don't worry if it could not be mirrored, some individual files may fail but can be manually recovered later
        timeout-minutes: 595 # max time out is 600, quit and at least try to commit / push what was downloaded so far 
        run: wget --no-verbose --execute robots=off --random-wait --wait 15 --recursive -level=inf --no-parent --convert-links --page-requisites --content-on-error --content-disposition "${URL}"
        env:
          URL: ${{ steps.target.outputs.url }}

      - name: Remove Files Over 100 Megabytes
        working-directory: ${{ steps.target.outputs.directory }}
        run: find . -size +100M | xargs -IFILE rm -rf FILE

      # See also https://gist.github.com/vpadhariya/90ab71c2a6a1203f5f9aa75ad5c5f32a
      - name: Clean up query strings
        continue-on-error: true # Don't worry if files could not be converted, just get it pushed
        working-directory: ${{ steps.target.outputs.directory }}
        run: for i in `find $1 -type f -name "*\?*"`; do mv $i `echo $i | cut -d? -f1`; done

      - name: Push Downloaded Directory
        id: auto-commit
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          file_pattern: .
          create_branch: true
          branch: ${{ steps.target.outputs.branch }}
          commit_author: norwd <106889957+norwd@users.noreply.github.com>
          commit_user_name: norwd
          commit_user_email: 106889957+norwd@users.noreply.github.com
          commit_options: -s -S
          commit_message: |
            Download ${{ steps.target.outputs.directory }}

            Original source: ${{ steps.target.outputs.url }}

            **NOTE:** This is an automatic commit. See the archive workflow.

      - name: Create Pull Request
        if: ${{ steps.auto-commit.outputs.changes_detected == 'true' || steps.auto-commit-cleanup.outputs.changes_detected == 'true' }}
        run: gh --repo "${{ github.repository }}" pr create --title "${TITLE}" --body "${BODY}" --base "${BASE}" --head "${HEAD}" | tee -a "${GITHUB_STEP_SUMMARY}" | tee -a pr.txt
        env:
          BASE: ${{ github.ref_name }}
          HEAD: ${{ steps.target.outputs.branch }}
          TITLE: "Archive ${{ steps.target.outputs.directory }}"
          BODY: |
            Original source: [${{ steps.target.outputs.url }}](<${{ steps.target.outputs.url }}>)

            **NOTE:** This is an automatic commit. See the archive workflow.

  archive-file:
    if: ${{ !endsWith(inputs.url, '/') }}
    name: Archive File
    runs-on: ubuntu-latest
    timeout-minutes: 660
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.AUTO_DOWNLOAD_ARCHIVE }}

      - name: Setup GPG Keys
        uses: crazy-max/ghaction-import-gpg@v5
        with:
          gpg_private_key: ${{ secrets.AUTO_COMMIT_GPG_PRIVATE_KEY_ARCHIVE }}
          passphrase: ${{ secrets.AUTO_COMMIT_GPG_PASSPHRASE_ARCHIVE }}
          git_user_signingkey: true
          git_commit_gpgsign: true

      - name: Determine Target
        id: target
        env: { URL: '${{ inputs.url }}' }
        run: |
          grep --invert "^#" << EOF | tee -a "${GITHUB_OUTPUT}"

          # Get the directory to save the file into
          directory=$(
            dirname "$(
              echo "${URL}" |
                python3 -c "import sys; from urllib.parse import unquote; print(unquote(sys.stdin.read()));" |
                sed -E 's/^https?:\/\/web.archive.org\/web\/[0-9]+\/(https?:\/\/)?/https:\/\//' |
                sed -E 's/^https?:\/\///' |
                sed -E 's/^ftps?:\/\///' |
                sed -E 's/^ia[0-9]+.us.archive.org\/[0-9]+\/items\//archive.org\/download\//'
            )"
          )

          # Get the name of the file being saved  
          file=$(
            basename "${URL}" |
            python3 -c "import sys; from urllib.parse import unquote; print(unquote(sys.stdin.read()));"
          )

          # Get the url of the file (with any sanitisation)
          url=$(
            echo "${URL}"
          )

          # Get the branch that this url will be archived via
          branch=$(
            echo "archive/${{ github.run_id }}-${{ github.run_number }}-${{ github.run_attempt }}-$(openssl rand -hex 8)"
          )

          EOF

      - name: Create Target Directory
        run: mkdir -p "${DIR}"
        env:
          DIR: ${{ steps.target.outputs.directory }}

      - name: Download File
        working-directory: ${{ steps.target.outputs.directory }}
        run: wget --no-verbose --execute robots=off --random-wait --wait 5 --output-document "${FILE}" "${URL}"
        env:
          URL: ${{ steps.target.outputs.url }}
          FILE: ${{ steps.target.outputs.file }}

      - name: Split PDF File By Page
        if: ${{ endsWith(steps.target.outputs.file, '.pdf') }}
        working-directory: ${{ steps.target.outputs.directory }}
        run: |
          sudo apt-get install pdftk                                # Install tool to split PDF
          pdftk "${FILE}" burst output "${FILE%%.*}_pg_%04d.pdf"    # Split PDF into one doc per page
          find . -size +100M | xargs -IFILE rm -rf FILE             # Remove any files over 100M (i.e. original if it was too big)
        env:
          FILE: ${{ steps.target.outputs.file }}

      - name: Push Downloaded File
        id: auto-commit
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          file_pattern: .
          create_branch: true
          branch: ${{ steps.target.outputs.branch }}
          commit_author: norwd <106889957+norwd@users.noreply.github.com>
          commit_user_name: norwd
          commit_user_email: 106889957+norwd@users.noreply.github.com
          commit_options: -s -S
          commit_message: |
            Download ${{ steps.target.outputs.file }}

            Original source: ${{ steps.target.outputs.url }}

            **NOTE:** This is an automatic commit. See the archive workflow.

      - name: Create Pull Request
        if: ${{ steps.auto-commit.outputs.changes_detected == 'true' }}
        run: gh --repo "${{ github.repository }}" pr create --title "${TITLE}" --body "${BODY}" --base "${BASE}" --head "${HEAD}" | tee -a "${GITHUB_STEP_SUMMARY}" | tee -a pr.txt
        env:
          BASE: ${{ github.ref_name }}
          HEAD: ${{ steps.target.outputs.branch }}
          TITLE: "Archive ${{ steps.target.outputs.file }}"
          BODY: |
            Original source: [${{ steps.target.outputs.url }}](<${{ steps.target.outputs.url }}>)

            **NOTE:** This is an automatic commit. See the archive workflow.

      - name: Approve Pull Request
        continue-on-error: true # Don't worry if it can't merge, the PR can be manually merged later
        if: ${{ steps.auto-commit.outputs.changes_detected == 'true' }}
        run: gh --repo "${{ github.repository }}" pr merge --auto --merge "$(cat pr.txt)"
